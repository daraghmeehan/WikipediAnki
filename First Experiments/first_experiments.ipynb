{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ad7d5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, wikipedia, spacy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import ast # for converting string representation of list to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2498c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/Earth\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "title = soup.find(id=\"firstHeading\").text\n",
    "print(title)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf46f3e",
   "metadata": {},
   "source": [
    "## First thing\n",
    "\n",
    "Just first paragraph, choose sentence number when presented, and choose to edit or use links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2ea4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c382a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting first paragraph\n",
    "for i in range(len(all_paragraphs)):\n",
    "    p = all_paragraphs[i]\n",
    "    if p.text == \"\\n\": # avoids \\n paragraph which comes first\n",
    "        continue\n",
    "    else:\n",
    "        break # only one for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "931f0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose which line to learn from, or go back with b.\n",
      "1) Earth is the third planet from the Sun and the only astronomical object known to harbor life.\n",
      "2) While large volumes of water can be found throughout the Solar System, only Earth sustains liquid surface water.\n",
      "3) About 71% of Earth's surface is made up of the ocean, dwarfing Earth's polar ice, lakes, and rivers.\n",
      "4) The remaining 29% of Earth's surface is land, consisting of continents and islands.\n",
      "5) Earth's surface layer is formed of several slowly moving tectonic plates, interacting to produce mountain ranges, volcanoes, and earthquakes.\n",
      "6) Earth's liquid outer core generates the magnetic field that shapes Earth's magnetosphere, deflecting destructive solar winds.\n",
      "What line do you want to learn? 6\n",
      "\n",
      "Which words would you like to hide?\n",
      "1 Earth\n",
      "2 's\n",
      "3 liquid\n",
      "4 outer\n",
      "5 core\n",
      "6 generates\n",
      "7 the\n",
      "8 magnetic\n",
      "9 field\n",
      "10 that\n",
      "11 shapes\n",
      "12 Earth\n",
      "13 's\n",
      "14 magnetosphere\n",
      "15 ,\n",
      "16 deflecting\n",
      "17 destructive\n",
      "18 solar\n",
      "19 winds\n",
      "20 .\n",
      "Select a span (e.g. \"[1,2,3]\"), a single word (e.g. \"[5]\"), or even a multiple spans (e.g. \"[[1,2], [5,6]]\"\n",
      "[[14], [18,19]]\n",
      "\n",
      "Your new flashcard will look like this:\n",
      "Earth's liquid outer core generates the magnetic field that shapes Earth's [1], deflecting destructive [2] [2].\n",
      "\n",
      "And the answers are:\n",
      "1 magnetosphere\n",
      "2 solar winds\n"
     ]
    }
   ],
   "source": [
    "p_text = p.text.strip()\n",
    "doc = nlp(p_text)\n",
    "\n",
    "sents = list(doc.sents) # all sentences are type spacy.tokens.span.Span\n",
    "number_of_sents = len(list(doc.sents))\n",
    "\n",
    "print(\"Choose which line to learn from, or go back with b.\")\n",
    "\n",
    "for i in range(1, len(sents) + 1):\n",
    "    print(f\"{i}) {sents[i - 1]}\")\n",
    "\n",
    "# ask user, line 6 is interesting enough to create a flashcard for\n",
    "line_number_to_learn = input(\"What line do you want to learn? \")\n",
    "\n",
    "if line_number_to_learn == \"b\":\n",
    "    raise # go back here!!\n",
    "else:\n",
    "    line_number_to_learn = int(line_number_to_learn)\n",
    "    \n",
    "if line_number_to_learn not in list(range(1, number_of_sents + 1)):\n",
    "    print(\"Please try again and choose a valid line, or go back with b.\")\n",
    "    raise # instead of exit as it kills kernel # ask again!!\n",
    "\n",
    "print(\"\\nWhich words would you like to hide?\")\n",
    "\n",
    "line_to_learn = sents[line_number_to_learn - 1]\n",
    "for i in range(1, len(line_to_learn) + 1):\n",
    "    print(f\"{i} {line_to_learn[i - 1]}\")\n",
    "\n",
    "# [[14], [18,19]] for line 6 generates two interesting answers\n",
    "selected_spans_str = input(f\"Select a span (e.g. \\\"[1,2,3]\\\"), a single word (e.g. \\\"[5]\\\"), or even a multiple spans (e.g. \\\"[[1,2], [5,6]]\\\"\\n\")\n",
    "\n",
    "all_spans = [] # to track all the spans mentioned\n",
    "span_numbers = {} # to track, for a given index, which span group (i.e. the answer) it corresponds to\n",
    "answers = [] # to collect the answers for the given sub_spans\n",
    "\n",
    "try:\n",
    "    selected_spans = ast.literal_eval(selected_spans_str)\n",
    "    assert isinstance(selected_spans, list)\n",
    "    \n",
    "    if isinstance(selected_spans[0], int):\n",
    "        # if only have one span, e.g. \"[1,2,3]\" or \"[5]\"\n",
    "        selected_spans = [selected_spans] # can trivially treat as a nested span\n",
    "        \n",
    "    elif not isinstance(selected_spans[0], list):\n",
    "        raise\n",
    "    \n",
    "    # now have a list of spans \"[[1,2], [5,6]]\", or simply \"[[1,2,3]]\"\n",
    "    all_spans = [idx for sub_span in selected_spans for idx in sub_span] # simply extracting every word index from our list of lists\n",
    "    for i, sub_span in enumerate(selected_spans, start = 1):\n",
    "        # now building answer for given sub_span, and assigning span numbers (corresponding answer) for each index of the sub-span\n",
    "        answer = \"\"\n",
    "\n",
    "        for j, idx in enumerate(sub_span, start=1):\n",
    "            span_numbers[idx] = i # assigns indiviual index to a specific span (answer), to use when creating the flashcard\n",
    "            \n",
    "            if j != len(sub_span):\n",
    "                answer += line_to_learn[idx - 1].text_with_ws\n",
    "            else:\n",
    "                # don't add whitespace if at the last sub_span index (don't want an answer with a space at the end)\n",
    "                answer += line_to_learn[idx - 1].text\n",
    "        \n",
    "        answers.append(answer)\n",
    "\n",
    "\n",
    "except:\n",
    "    print(\"Please try again with a valid span.\")\n",
    "\n",
    "\n",
    "print(\"\\nYour new flashcard will look like this:\")\n",
    "\n",
    "question = \"\"\n",
    "for i in range(1, len(line_to_learn) + 1):\n",
    "    token = line_to_learn[i - 1]\n",
    "    if i in all_spans:\n",
    "        span_number = span_numbers[i] # like a reverse dict search\n",
    "        question += f\"[{span_number}]\"\n",
    "        question += token.whitespace_\n",
    "    else:\n",
    "        question += token.text_with_ws\n",
    "print(question)\n",
    "print(\"\\nAnd the answers are:\")\n",
    "for i, answer in enumerate(answers, start = 1):\n",
    "    print(f\"{i} {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c5bb8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Earth's liquid outer core generates the magnetic field that shapes Earth's [1], deflecting destructive solar winds.\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_spans = [14] # all spans the user has chosen\n",
    "question = \"\"\n",
    "for i in range(1, len(line_to_learn) + 1):\n",
    "    token = line_to_learn[i - 1]\n",
    "    if i in all_spans:\n",
    "        span_number = 1 # reverse dict search here\n",
    "        question += f\"[{span_number}]\"\n",
    "        question += token.whitespace_\n",
    "    else:\n",
    "        question += token.text_with_ws\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba1ece0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## need javascript to edit stuff!! ##\n",
    "\n",
    "# for i in range(len(all_paragraphs)):\n",
    "#     p = all_paragraphs[i]\n",
    "#     if p.text == \"\\n\": # avoids \\n first line\n",
    "#         continue\n",
    "    \n",
    "#     tag = soup.new_tag(\"b\") # making a bold element\n",
    "#     tag.string = f\"PARAGRAPH {i}:\"\n",
    "#     p.insert_before(tag)\n",
    "    \n",
    "# #     print(p)\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad20e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"../{title} - Modified.html\", \"wb\") as f_output:\n",
    "#     f_output.write(soup.prettify(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fcd59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d557360",
   "metadata": {},
   "source": [
    "## First things after first useful thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba68ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# press 0.1, 0.2, 0.3 for summary paragraphs and 1.1, 2.1 etc for section/subsection\n",
    "\n",
    "\n",
    "# otherwise want summaries of different links, want search function through them\n",
    "# or else to move to a different site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf2f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498bb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "764fd4e9",
   "metadata": {},
   "source": [
    "# Retrieving all useful elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcab37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title to be placed at top of every flashcard...\n",
    "# infobox is <table class=\"infobox\">\n",
    "# key_paragraphs are <p>s before table of contents\n",
    "# tocs is <div id=\"toc\" class=\"toc\">\n",
    "# h2s after that are different section names (can add to flashcards too)\n",
    "# <p>s between are the text\n",
    "# h3s are subsubsections etc -> recursively get these after "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271c9f0",
   "metadata": {},
   "source": [
    "# UI Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f48f3e",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c10f91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What page do you want to learn from?https://en.wikipedia.org/wiki/Earth\n"
     ]
    }
   ],
   "source": [
    "# wikipedia_url = \"https://en.wikipedia.org/wiki/Barack\" # an example where the redirected address != the given address\n",
    "wikipedia_url = input(\"What page do you want to learn from?\")\n",
    "try:\n",
    "    r = requests.get(wikipedia_url, allow_redirects=True)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    redirected_address = soup.find(\"link\", rel=\"canonical\").get(\"href\")\n",
    "    assert wikipedia_url == redirected_address\n",
    "except:\n",
    "    print(\"Please try again with a valid Wikipedia page.\\nThis includes the correct redirected address.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45e19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89609f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb45c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_inputs = [\n",
    "    \"h\", # home\n",
    "    \"c\", # contents\n",
    "    \"b\", # back\n",
    "    \"1.1.1\", #??\n",
    "    \"i\", # infobox\n",
    "    \"pp\", # page previews and select by typing it, then select how many sentences, give number or list of sentences then edit text\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c6424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a2022fc",
   "metadata": {},
   "source": [
    "### Useful extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e59ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import os\n",
    "\n",
    "# base = os.path.dirname(os.path.abspath(__file__))\n",
    "# html = open(os.path.join(base, 'example.html'))\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# for i in soup.find('div', {\"id\":None}).findChildren():\n",
    "#     i.replace_with('##')\n",
    "\n",
    "# with open(\"example_modified.html\", \"wb\") as f_output:\n",
    "#     f_output.write(soup.prettify(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a056a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_text = re.sub('(\\[[0-9]+\\])', '', unicodedata.normalize('NFKD', p.text)).strip()\n",
    "#         if cleaned_text:\n",
    "#             yield cleaned_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
